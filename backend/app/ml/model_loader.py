import os
import json
import tensorflow as tf
from typing import Optional, List
import logging

logger = logging.getLogger(__name__)

class ModelLoader:
    """Gestionnaire de chargement et de configuration du mod√®le ML"""
    
    def __init__(self):
        self.model: Optional[tf.keras.Model] = None
        self.class_names: List[str] = []
        self.model_loaded: bool = False
        self.model_path: str = ""
        self.class_names_path: str = ""
        
    def configure_paths(self, model_path: str = None, class_names_path: str = None):
        """Configure les chemins vers le mod√®le et les classes"""
        if model_path is None:
            self.model_path = os.path.join("app", "ml", "plant_disease_model.h5")
        else:
            self.model_path = model_path
            
        if class_names_path is None:
            self.class_names_path = os.path.join("app", "ml", "class_names.json")
        else:
            self.class_names_path = class_names_path
    
    def load_model(self) -> bool:
        """Charge le mod√®le TensorFlow"""
        try:
            if not os.path.exists(self.model_path):
                logger.error(f"Mod√®le non trouv√© √† {self.model_path}")
                return False
            
            # Charger le mod√®le avec gestion des erreurs TensorFlow
            self.model = tf.keras.models.load_model(
                self.model_path,
                compile=False  # √âvite les erreurs de compilation
            )
            
            logger.info(f"‚úÖ Mod√®le TensorFlow charg√© depuis {self.model_path}")
            logger.info(f"Architecture du mod√®le: {self.model.input_shape} -> {self.model.output_shape}")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors du chargement du mod√®le: {str(e)}")
            self.model = None
            return False
    
    def load_class_names(self) -> bool:
        """Charge les noms des classes depuis le fichier JSON"""
        try:
            if not os.path.exists(self.class_names_path):
                logger.error(f"Fichier class_names.json non trouv√© √† {self.class_names_path}")
                return False
            
            with open(self.class_names_path, 'r', encoding='utf-8') as f:
                self.class_names = json.load(f)
            
            logger.info(f"‚úÖ {len(self.class_names)} classes charg√©es")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors du chargement des classes: {str(e)}")
            self.class_names = []
            return False
    
    def initialize(self) -> bool:
        """Initialise compl√®tement le mod√®le et les classes"""
        self.configure_paths()
        
        model_loaded = self.load_model()
        classes_loaded = self.load_class_names()
        
        self.model_loaded = model_loaded and classes_loaded
        
        if self.model_loaded:
            logger.info("üöÄ Mod√®le ML initialis√© avec succ√®s")
        else:
            logger.warning("‚ö†Ô∏è √âchec de l'initialisation du mod√®le ML")
        
        return self.model_loaded
    
    def get_model_info(self) -> dict:
        """Retourne les informations sur le mod√®le charg√©"""
        if not self.model_loaded:
            return {"status": "not_loaded", "error": "Mod√®le non charg√©"}
        
        return {
            "status": "loaded",
            "model_path": self.model_path,
            "input_shape": str(self.model.input_shape) if self.model else None,
            "output_shape": str(self.model.output_shape) if self.model else None,
            "classes_count": len(self.class_names),
            "model_loaded": self.model_loaded
        }
    
    def validate_model(self) -> bool:
        """Valide que le mod√®le est pr√™t pour les pr√©dictions"""
        if not self.model_loaded or self.model is None:
            return False
        
        try:
            # Test avec une image factice
            import numpy as np
            test_input = np.random.random((1, 224, 224, 3)).astype(np.float32)
            _ = self.model.predict(test_input, verbose=0)
            return True
        except Exception as e:
            logger.error(f"Validation du mod√®le √©chou√©e: {str(e)}")
            return False

# Instance globale du chargeur de mod√®le
model_loader = ModelLoader()
